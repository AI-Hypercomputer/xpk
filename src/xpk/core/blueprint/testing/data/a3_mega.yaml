# Copyright 2024 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

---
!Blueprint
blueprint_name: xpk-gke-a3-megagpu
toolkit_modules_url: github.com/GoogleCloudPlatform/cluster-toolkit
toolkit_modules_version: v1.62.2

vars:
  project_id: "foo"
  deployment_name: xpk-gke-a3-megagpu
  region: us-central1
  zone: us-central1-c
  labels: {gke_product_type: xpk}

deployment_groups:
- !DeploymentGroup
  group: primary
  modules:
  - !DeploymentModule
    id: network1
    source: modules/network/vpc
    settings:
      subnetwork_name: bar-xpk-gke-a3-megagpu-subnet
      secondary_ranges:
        bar-xpk-gke-a3-megagpu-subnet:
        - range_name: pods
          ip_cidr_range: 10.4.0.0/14
        - range_name: services
          ip_cidr_range: 10.0.32.0/20
  - !DeploymentModule
    id: gpunets
    source: modules/network/multivpc
    settings:
      network_name_prefix: bar-gpunet
      global_ip_address_range: 192.169.0.0/16
      network_count: 8
      subnetwork_cidr_suffix: 24
  - !DeploymentModule
    id: gke_cluster
    source: modules/scheduler/gke-cluster
    use: [network1, gpunets]
    settings:
      release_channel: RAPID
      version_prefix: '1.2'
      min_master_version: 1.2.3
      prefix_with_deployment_name: false
      name_suffix: bar
      enable_private_endpoint: false
      enable_gcsfuse_csi: true
      enable_filestore_csi: true
      master_authorized_networks:
      - cidr_block: 10.0.0.0/32  # Allows your machine run kubectl command. It's required for the multi-network setup.
        display_name: "kubectl-access-network"
      system_node_pool_machine_type: "e2-standard-32"
      system_node_pool_node_count:
        total_min_nodes: 5
        total_max_nodes: 1000
      k8s_network_names:
        gvnic_prefix: "bar-gpunet-"
        gvnic_postfix: "-subnet"
        gvnic_start_index: 0
    outputs: [instructions]

  - !DeploymentModule
    id: a3_megagpu_pool_0
    source: modules/compute/gke-node-pool
    use: [gke_cluster, gpunets]
    settings:
      name: bar-a3-megagpu-pool-0
      machine_type: a3-megagpu-8g
      zones: [us-central1-c]
      host_maintenance_interval: 'PERIODIC'
      reservation_affinity:
        consume_reservation_type: SPECIFIC_RESERVATION
        specific_reservations:
        - name: test-reservation
      run_workload_script: false
      spot: false
      max_pods_per_node: 32
      guest_accelerator:
      - type: nvidia-h100-mega-80gb
        count: 8
        gpu_driver_installation_config:
          gpu_driver_version: "LATEST"
      auto_upgrade: true
      static_node_count: 2
      placement_policy:
        type: COMPACT
        name: test-reservation-placement
    outputs: [instructions]

  - !DeploymentModule
    id: workload_component_install
    source: modules/management/kubectl-apply
    use: [gke_cluster]
    settings:
      jobset:
        install: true
        version: v0.7.2
      apply_manifests:
      - source: $(ghpc_stage("xpk-gke-a3-megagpu"))/storage_crd.yaml

  - !DeploymentModule
    id: workload_configmap
    source: modules/management/kubectl-apply
    use: [gke_cluster]
    settings:
      apply_manifests:
      - source: $(ghpc_stage("xpk-gke-a3-megagpu"))/config-map.yaml.tftpl
        template_vars: {
          resource_config_name: "bar-resources-configmap",
          num_nodes: "2",
          cluster_config_name: "bar-metadata-configmap",
          capacity_type: "reservation",
          reservation: "test-reservation",
          }
